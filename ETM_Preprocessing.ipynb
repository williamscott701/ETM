{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install nltk\n",
    "# !pip install pandas\n",
    "# !pip install numpy num2words\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# # !pip install ipython-autotime\n",
    "\n",
    "# # %load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from num2words import num2words\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"20_newsgroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(str(os.getcwd())+'/'+title+'/alt.atheism'):\n",
    "    for i in filenames:\n",
    "        paths.append(str(dirpath)+str(\"/\")+i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_doc(id):\n",
    "    file = open(paths[id], 'r', encoding='cp1250')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(k):\n",
    "    for i in range(len(k)):\n",
    "        try:\n",
    "            k[i] = num2words(int(k[i]))\n",
    "        except:\n",
    "            pass\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(pd):\n",
    "    pd = pd.str.lower()\n",
    "    pd = pd.str.replace('[{}]'.format('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\\t'), ' ')\n",
    "    pd = pd.apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])\n",
    "    pd = pd.apply(lambda x: convert_numbers(x))\n",
    "    pd = pd.str.join(' ')\n",
    "    pd = pd.str.replace('[{}]'.format(string.punctuation), ' ')\n",
    "    \n",
    "    pd = pd.apply(lambda x: [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(x)])    \n",
    "    pd = pd.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    pd = pd.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "    return pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "doc = 0\n",
    "docs = []\n",
    "\n",
    "for path in paths:\n",
    "    file = open(path, 'r', encoding='cp1250')\n",
    "    text = file.read().strip()\n",
    "    file.close()\n",
    "    \n",
    "    docs.append(text)\n",
    "    \n",
    "    if doc%700 == 0:\n",
    "        print(doc)\n",
    "        \n",
    "    doc += 1\n",
    "docs_pd = pd.DataFrame(docs)\n",
    "docs_pd[0] = preprocess(docs_pd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[newsgroup, alt, atheism, path, cantaloup, srv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[newsgroup, alt, atheism, path, cantaloup, srv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[path, cantaloup, srv, c, cmu, edu, da, news, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[path, cantaloup, srv, c, cmu, edu, crabappl, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[path, cantaloup, srv, c, cmu, edu, da, news, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  [newsgroup, alt, atheism, path, cantaloup, srv...\n",
       "1  [newsgroup, alt, atheism, path, cantaloup, srv...\n",
       "2  [path, cantaloup, srv, c, cmu, edu, da, news, ...\n",
       "3  [path, cantaloup, srv, c, cmu, edu, crabappl, ...\n",
       "4  [path, cantaloup, srv, c, cmu, edu, da, news, ..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "\n",
    "for i in docs_pd.values:\n",
    "    unique_words = unique_words | set(i[0])\n",
    "unique_words = list(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12041"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unique_words).to_csv(\"word.txt\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indexes(doc):\n",
    "    string = \"\"\n",
    "    for i in doc:\n",
    "        ind = unique_words.index(i)\n",
    "        string += str(ind) + \" \"\n",
    "    string = string[:-1]\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    }
   ],
   "source": [
    "docs_indices = []\n",
    "for idx, i in enumerate(docs_pd.values):\n",
    "    docs_indices.append(get_indexes(i[0]))\n",
    "    if idx % 100 == 0:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20 6348 1479 8012 450 5892 1599 5390 4013 7520 5892 1599 5390 4013 880 8857 5390 4013 2102 3689 5390 4013 1231 2039 360 4013 8353 10936 2039 360 4013 3073 2965 11008 2314 2102 1613 1392 8698 8120 1541 11261 5432 4488 4428 1392 3038 7235 2080 11671 2426 6530 7476 11600 3210 6530 11880 30 6530 6898 30 11600 4930 6530 9602 3359 1383 6008 5442 8503 11298 3087 6355 4201 5457 2426 6530 6898 3210 5027 10329 2426 11600 2426 6530 3211 4930 30 4488 4428 1392 1623 1541 1257 1392 4067 9093 8709 30 6530 9602 3932 11098 11098 30 3862 1570 5245 8521 2261 921 11880 553 30 11600 2426 6530 3211 3281 9602 3281 4201 9602 4757 7847 11377 5677 4428 3281 3281 4835 6972 2261 921 11880 553 30 11600 2426 6530 3211 3281 6225 6972 9602 30 6530 11214 11214 5442 8503 11298 9014 2102 10370 7235 9481 9663 4735 9737 5381 11214 4735 3932 7644 2636 7629 4835 8561 8307 635 3932 3719 752 7476 4979 2659 5577 8579 7999 4802 1929 2467 977 11041 5983 3407 7235 4201 11098 5903 30'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_indices_pd = pd.DataFrame(docs_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_indices_pd.to_csv(\"sentences.txt\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
